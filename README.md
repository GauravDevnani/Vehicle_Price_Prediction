# ğŸŒŸVehicle Price PredictionğŸŒŸ
## Vehicle Price Prediction & Market Analysis

### Overview
This project leverages the "Vehicle Dataset 2024" to explore the new vehicle market, perform comprehensive Exploratory Data Analysis (EDA), and develop predictive models for vehicle prices. It's designed to demonstrate various data science applications, from data cleaning to advanced regression techniques.

### Dataset
The "Vehicle Dataset 2024" offers a detailed snapshot of new vehicles, including SUVs, cars, trucks, and vans, currently available in the market. It's a rich resource for anyone looking to practice and apply data science skills.

Size: Contains 1002 entries across 18 columns.

***Column Descriptors***

ğŸ¯***name:*** The full name of the vehicle, including make, model, and trim.

ğŸ¯***description:*** A brief description of the vehicle, often including key features and selling points.

ğŸ¯***make:*** The manufacturer of the vehicle (e.g., Ford, Toyota, BMW).

ğŸ¯***model:*** The model name of the vehicle.

ğŸ¯***type:*** The type of the vehicle, which is "New" for all entries in this dataset.

ğŸ¯***year:*** The year the vehicle was manufactured.

ğŸ¯***price:*** The price of the vehicle in USD.

ğŸ¯***engine:*** Details about the engine, including type and specifications.

ğŸ¯***cylinders:*** The number of cylinders in the vehicle's engine.

ğŸ¯***fuel:*** The type of fuel used by the vehicle (e.g., Gasoline, Diesel, Electric).

ğŸ¯***mileage:*** The mileage of the vehicle, typically in miles.

ğŸ¯***transmission:*** The type of transmission (e.g., Automatic, Manual).

ğŸ¯***trim:*** The trim level of the vehicle, indicating different feature sets or packages.

ğŸ¯***body:*** The body style of the vehicle (e.g., SUV, Sedan, Pickup Truck).

ğŸ¯***doors:*** The number of doors on the vehicle.

ğŸ¯***exterior_color:*** The exterior color of the vehicle.

ğŸ¯***interior_color:*** The interior color of the vehicle.

ğŸ¯***drivetrain:*** The drivetrain of the vehicle (e.g., All-wheel Drive, Front-wheel Drive).


### Data Science Applications
This rich dataset enables a wide array of data science applications:

ğŸª„***Price Prediction:*** Develop regression models to accurately predict vehicle prices based on attributes like make, model, year, and mileage.

ğŸª„***Market Analysis:*** Identify trends in vehicle types, brands, and pricing dynamics, perform market segmentation, and gain insights into consumer preferences.

ğŸª„***Descriptive Statistics:*** Conduct thorough descriptive statistical analyses to summarize and understand the central tendencies, spread, and distributions of key features.

ğŸª„***Visualization:*** Create compelling visualizations to illustrate the distribution of prices, mileage, and other features across different vehicle types, fuels, and drivetrains.

ğŸª„***Data Cleaning:*** Practice essential data cleaning techniques, including handling missing values, identifying and addressing outliers, and transforming data for optimal analysis.

ğŸª„***Feature Engineering:*** Innovate by developing new, impactful features (e.g., price per year, mileage per year) to enhance model performance and uncover deeper patterns.


### Exploratory Data Analysis (EDA)
The EDA phase in the Vehicle_Price_Prediction.ipynb notebook involves:

âš¡***Initial Data Inspection:*** Checking for missing values (NaN values) and reviewing data types for each column.

âš¡***Descriptive Statistics:*** Generating statistical summaries for numerical columns to understand their range, mean, standard deviation, etc.

âš¡***Univariate Analysis:*** Analyzing the distribution of individual features like price, mileage, year, cylinders, and doors using histograms, box plots, and count plots.

âš¡***Bivariate Analysis:*** Exploring relationships between price and other features (e.g., make, body, fuel, transmission, drivetrain, exterior_color, interior_color). This helps identify potential correlations and influences on vehicle pricing.

âš¡***Outlier Detection:*** Visual identification of outliers in numerical features that might require special handling.


### Data Preprocessing
âœ”ï¸***Handling Missing Values:*** Strategies to address any missing data points (though the current dataset might be relatively clean).

âœ”ï¸***Categorical Encoding:*** Converting categorical features (like make, model, fuel, etc.) into numerical representations suitable for machine learning models, typically using one-hot encoding or label encoding.

âœ”ï¸***Feature Selection:*** Identifying and selecting the most relevant features for predicting vehicle prices, potentially using techniques like SelectKBest with f_regression.

âœ”ï¸***Train-Test Split:*** Splitting the processed data into training and testing sets for model development and evaluation.


### Price Prediction Models
This project explores various regression models to predict vehicle prices, including:

âš¡***Linear Regression:*** A baseline model for understanding linear relationships.

âš¡***Decision Tree Regressor:*** A non-linear model capable of capturing complex decision rules.

âš¡***Random Forest Regressor:*** An ensemble method that combines multiple decision trees to improve accuracy and reduce overfitting.


### Model Tuning
***Hyperparameter tuning*** (e.g., using GridSearchCV) is applied to optimize the performance of the Decision Tree and Random Forest models.


### Results
The performance of the predictive models is evaluated using standard regression metrics:

ğŸ¯***Mean Squared Error (MSE):*** Measures the average squared difference between the estimated values and the actual value.

ğŸ¯***R-squared (R^2) Score:*** Indicates how well the model's predictions fit the observed data. A higher R^2value (closer to 1) indicates a better fit.

***Example Results*** (from notebook evaluation):
Tuned Decision Tree: MSE: ~126,121,141.75, R^2: ~0.505

Tuned Random Forest: MSE: ~126,014,601.83, R^2: ~0.506

These results suggest that while the models can explain about 50% of the variance in vehicle prices, there's still room for improvement, potentially through more advanced feature engineering, exploring other models (like gradient boosting), or acquiring more data.

